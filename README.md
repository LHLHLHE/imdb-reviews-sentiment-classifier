# Анализ тональности обзоров на фильмы с IMDb

## Постановка задачи

Построение сервиса для бинарной классификации тональности обзоров на фильмы с IMDb
(позитивный/негативный) на основе нейросетевой модели семейства BERT. Такой сервис может
использоваться для мониторинга удовлетворенности пользователей, автоматической модерации отзывов и
аналитики по фильмам.

## Формат входных и выходных данных

Для обучения данные представлены в формате датасета с 2 колонками: review - текст обзора на
английском и label - метка, отражающая тональность (0 - позитивный, 1 - негативный).

Для инференса\* на вход подается текст, на выходе будут вероятности по каждому классу.

## Метрики

Используются метрики Accuracy, Precision, Recall и F1‑score, оптимизация по F1 по негативным
обзорам. Датасет сбалансирован (50% позитивных, 50% негативных обзоров), поэтому Accuracy остаётся
информативной, но F1 лучше отражает баланс Precision/Recall. Ожидается значение Accuracy/F1 0.89+.

## Валидация и тест

Датасет уже разделен на train и test, для валидации делается стратифицированный сплит train (80/20)
с фиксированным random_seed для воспроизводимости.

## Датасеты

Для обучения и тестирования взят датасет ajaykarthick/imdb‑movie‑reviews
(https://huggingface.co/datasets/ajaykarthick/imdb-movie-reviews), в нем 50к записей (train - 40к,
test - 10к) объемом ~70MB. Из потенциальных проблем можно выделить наличие HTML-разметки, которая
удаляется на этапе предобработки, а также сложность в определении тональности из-за наличия сарказма
и смешанной тональности.

## Моделирование

### Бейзлайн

В качестве простейшего решения взята логистическая регрессия, обучаемая на TF-IDF признаках.

### Основная модель

В качестве основной модели используется bert-base-uncased
(https://huggingface.co/google-bert/bert-base-uncased). Дообучение производится путем заморозки всех
слоев, кроме последних 4-х, и добавления линейной головы под задачу. Для токенизации используется
токенизатор от этой же модели.

## Внедрение\*

Модель планируется использовать в формате сервиса, реализованного на FastAPI. Сервис будет упакован
в docker-контейнер. Сама модель будет храниться в локальном S3-хранилище, которое так же будет
крутиться в docker.

\*В рамках курса MLOps не реализовано

---

# Работа с проектом

## Setup

Разработка велась на `Python 3.12`

Клонирование репозитория:

```
git clone https://github.com/LHLHLHE/imdb-reviews-sentiment-classifier.git
```

После клонирования репозитория перейдите в его папку:

```
cd imdb-reviews-sentiment-classifier
```

Установите Poetry для управления зависимостями:

```
pip install uv
```

Установка зависимостей проекта:

```
uv sync
```

Установка хуков для pre-commit:

```
uv run pre-commit install
```

Запустите проверки:

```
uv run pre-commit run -a
```

## Train

### Данные

Перед обучением необходимо скачать и предобработать данные.

#### Получение данных

Для управления данными используется DVC, чтобы скачать нужную версию данных, выполните следующую
команду:

```
uv run python -m reviews_classifier.commands download_data_from_s3
```

Данные появятся в папке `data/` в корне проекта.

#### Предобработка данных

Чтобы обработать полученные данные, выполните следующую команду:

```
uv run python -m reviews_classifier.commands preprocess_data
```

Обработанные данные появятся в папке `processed_data/` в корне проекта.

### Обучение

Перед запуском обучения необходимо поднять `MLFlow` по адресу `127.0.0.1:8080`(или на любом другом,
но тогда надо изменить параметр `tracking_uri` в `configs/logging/logging.yaml`) в режиме
`--serve-artifacts`

Есть 2 варианта обучения:

Baseline:

```
uv run python -m reviews_classifier.commands train baseline
```

Основная модель

```
uv run python -m reviews_classifier.commands train bert
```
